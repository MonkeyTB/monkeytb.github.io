<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <title>BERT</title>
  <meta name="description" content="        ">
  <meta name="author" content="MonkeyTB">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="BERT">
  <meta name="twitter:description" content="        ">
  
  <meta property="og:type" content="article">
  <meta property="og:title" content="BERT">
  <meta property="og:description" content="        ">
  
  <link rel="icon" type="image/png" href="/images/favicon.png" />
  <link href="/images/favicon.png" rel="shortcut icon" type="image/png">
  
  <link rel="stylesheet" href="/css/main.css">
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
  
  <meta name="google-site-verification" content="1-1ZlHoRvM0T2FqPbW2S-qLgYXN6rsn52kErlMPd_gw" />

<!-- 站点统计 -->
  <script 
  async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
  </script>  

<!-- 百度统计 -->
  
  <script>
      var _hmt = _hmt || [];
      (function() {
        var hm = document.createElement("script");
        hm.src = "//hm.baidu.com/hm.js?7193fc529267517a0eea8035d7fede15";
        var s = document.getElementsByTagName("script")[0]; 
        s.parentNode.insertBefore(hm, s);
      })();
  </script>
  

<!-- google 统计 -->
  

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
  (adsbygoogle = window.adsbygoogle || []).push({
    google_ad_client: "ca-pub-9005224472374751",
    enable_page_level_ads: true
  });
</script>

</head>


  <body>

    <span class="mobile btn-mobile-menu">        
      <div class="nav_container">
         <nav class="nav-menu-item" style = "float:right">
            <i class="nav-menu-item">
              <a href="/#blog" title="" class="blog-button">  博客主页
              </a>
            </i>
            
                <i class="nav-menu-item">

                  <a href="/archive" title="archive" class="btn-mobile-menu__icon">
                      所有文章
                  </a>
                </i>
            
                <i class="nav-menu-item">

                  <a href="/tags" title="tags" class="btn-mobile-menu__icon">
                      标签
                  </a>
                </i>
            
                <i class="nav-menu-item">

                  <a href="/about" title="about" class="btn-mobile-menu__icon">
                      关于我
                  </a>
                </i>
            
          </nav>
      </div>
    </span>
    
    <header class="panel-cover panel-cover--collapsed" style="background-image: url('/images/background-cover.jpg')">
  <div class="panel-main">

    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">
        <!-- 头像效果-start -->
        <div class="ih-item circle effect right_to_left">            
            <a href="/#blog" title="前往 YiYao 的主页" class="blog-button">
                <div class="img"><img src="/images/avatar.jpg" alt="img"></div>
                <div class="info">
                    <div class="info-back">
                        <h2> 
                            
                        </h2>
                        <p>
                           
                                自然语言处理 / 机器学习
                            
                        </p>
                    </div>
                </div>
            </a>
        </div>
        <!-- 头像效果-end -->
        <h1 class="panel-cover__title panel-title"><a href="/#blog" title="link to homepage for YiYao" class="blog-button">YiYao</a></h1>
        
        <span class="panel-cover__subtitle panel-subtitle">个人站</span>
        
        <hr class="panel-cover__divider" />
        <p class="panel-cover__description">欢迎来到我的个人站~</p>
        <hr class="panel-cover__divider panel-cover__divider--secondary" />
        
        
        

        <div class="navigation-wrapper">
          <div>
            <nav class="cover-navigation cover-navigation--primary">
              <ul class="navigation">
                <li class="navigation__item"><a href="/#blog" title="" class="blog-button">博客主页</a></li>
                
                  <li class="navigation__item"><a href="/archive" title="archive">所有文章</a></li>
                
                  <li class="navigation__item"><a href="/tags" title="tags">标签</a></li>
                
                  <li class="navigation__item"><a href="/about" title="about">关于我</a></li>
                
              </ul>
            </nav>
          </div>          
        </div>


        </div>
      </div>
    </div>
    
    
    <div class="panel-cover--overlay cover-clear"></div>
    
  </div>
</header>


    <div class="content-wrapper">
        <div class="content-wrapper__inner">
            <head>
  <link rel="stylesheet" href="/css/post.css">
</head>

<article class="post-container post-container--single" itemscope itemtype="http://schema.org/BlogPosting">
  <header class="post-header">
    <h1 class="post-title">BERT</h1>
    <div class="post-meta">
      <img src="/images/calendar.png" width="20px"/> 
      <time datetime="2022-01-01 00:00:00 +0800" itemprop="datePublished" class="post-meta__date date">2022-01-01</time>  

      <span id="busuanzi_container_page_pv"> | 阅读：<span id="busuanzi_value_page_pv"></span>次</span>
    </p>
    </div>
  </header>

  
    <h2 class="post-title">目录</h2>
    <ul>
  <li><a href="#背景">背景</a></li>
  <li><a href="#前人工作">前人工作</a>
    <ul>
      <li><a href="#elmo">elmo</a></li>
      <li><a href="#gpt">gpt</a></li>
      <li><a href="#创新点">创新点</a></li>
      <li><a href="#工作">工作</a></li>
      <li><a href="#总结">总结</a></li>
    </ul>
  </li>
  <li><a href="#工作原理">工作原理</a>
    <ul>
      <li><a href="#mlm">MLM</a></li>
      <li><a href="#nsp">NSP</a></li>
    </ul>
  </li>
  <li><a href="#微调">微调</a></li>
  <li><a href="#训练相关">训练相关</a></li>
  <li><a href="#参考文献">参考文献</a></li>
</ul>

  

  <section class="post">
    <head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>

<p><strong>Bert</strong>全称Bidirectional Encoder Representations from Transformers，再多项NLP任务中引起了轰动，其关键技术创新在于用双向Transformer模型，区别于之前从左向右和从右向左拼接，并添加了MLM的新技术。下面将详细介绍。</p>

<h2 id="背景">背景</h2>

<p>​	计算机视觉领域，通过对大规模数据进行网络训练，然后迁移学习进行微调适用于新的任务，去的很好的效果。近年来，这样的任务也用于许多自然语言任务。在此之前比如ELMo、GPT等。</p>

<h2 id="前人工作">前人工作</h2>

<h3 id="elmo">elmo</h3>

<ul>
  <li>后续使用，根据任务构造结构</li>
</ul>

<h3 id="gpt">gpt</h3>

<ul>
  <li>后续使用，单向模型</li>
  <li>cloze task， 借鉴了mask model</li>
</ul>

<h3 id="创新点">创新点</h3>

<ul>
  <li>GPT的局限性，单向的，限制了任务的类型，比如情感分类等</li>
  <li>MLM（token） 、 NSP（句子）</li>
</ul>

<h3 id="工作">工作</h3>

<ul>
  <li>非监督的特征方法</li>
  <li>非监督的微调方法</li>
  <li>迁移学习</li>
  <li>细节
    <ul>
      <li>预训练</li>
      <li>微调</li>
      <li>模型架构：transformer</li>
      <li>模型参数</li>
      <li>切词：wordpiece
        <ul>
          <li>本意是为了减少词汇表，对一些低频词通过拆分表达，这么做的好处是通过拆分的方式对低频词做了相对较好的表达，相比直接用oov或者低频词表示来说，能学到更多的信息。</li>
        </ul>
      </li>
      <li>mask 概率
        <ul>
          <li>具体来说，文章作者在一句话中随机选择 15% 的词汇用于预测。对于在原句中被抹去的词汇， 80% 情况下采用一个特殊符号 [MASK] 替换， 10% 情况下采用一个任意词替换，剩余 10% 情况下保持原词汇不变。这么做的主要原因是：在后续微调任务中语句中并不会出现 [MASK] 标记，而且这么做的另一个好处是：预测一个词汇时，模型并不知道输入对应位置的词汇是否为正确的词汇（ 10% 概率），这就迫使模型更多地依赖于上下文信息去预测词汇，并且赋予了模型一定的纠错能力。上述提到了这样做的一个缺点，其实这样做还有另外一个缺点，就是每批次数据中只有 15% 的标记被预测，这意味着模型可能需要更多的预训练步骤来收敛。</li>
          <li>在 BERT 中训练语言模型是通过预测输入中随机选择的 15% 的标记来完成的。这些标记的预处理如下——80% 被替换为“[MASK]”标记，10% 被替换为随机单词，10% 使用原始单词。导致作者选择这种方法的直觉如下（感谢来自 Google 的 Jacob Devlin 的洞察力）：
            <ul>
              <li>如果我们在 100% 的情况下使用 [MASK]，该模型不一定会为非屏蔽词生成良好的标记表示。非屏蔽词仍然用于上下文，但该模型针对预测屏蔽词进行了优化。</li>
              <li>如果我们 90% 的时间使用 [MASK]，10% 的时间使用随机单词，这将告诉模型观察到的单词<em>永远不会</em>正确。</li>
              <li>如果我们 90% 的时间使用 [MASK]，10% 的时间保持相同的单词，那么模型可以简单地复制非上下文嵌入。</li>
            </ul>
          </li>
          <li>没有对这种方法的比率进行消融，它可能在不同的比率下效果更好。此外，模型性能没有通过简单地屏蔽 100% 的选定标记进行测试。</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="总结">总结</h3>

<ul>
  <li>双向性</li>
  <li>生成类工作不方便
    <ul>
      <li>生成类工作不方便不代表不能用于生成任务，我们可以通过对生成结果进行mask，而模拟出生成效果，具体来说就是生成任务只能看到上文，而不能看到下文，与Bert的任务冲突，但是我们对生成部分用上三角mask，通过这种方式可以保证在生成的过程中只能看到上文，而看不到下文，这样就可以用Bert来做生成任务啦！</li>
    </ul>
  </li>
</ul>

<h2 id="工作原理">工作原理</h2>

<p>​	使用了Transformer，这是一种注意力机制，可以学习文本单词之间的上下文信息。普通的Transformer包含两部分，读取文本输入的编码器和生成的解码器，Bert任务的目标是生成语言模型，因此只需要编码器机制。Transformer介绍<a href="https://monkeytb.github.io/2021/12/Transformer/">$\color{red}{Transformer探索}$</a>。</p>

<h3 id="mlm">MLM</h3>

<p>​	将单词序列输入Bert之前，每个序列中15%的单词被替换为[MASK]标记，然后Bert尝试根据非屏蔽的上下文来预测屏蔽的原始词。技术角度来讲需要以下几点：</p>

<ul>
  <li>在编码器输出之上添加一个分类层；</li>
  <li>将输出向量乘以嵌入矩阵，将他们转换为词汇维度；</li>
  <li>用softmax计算词汇表中每个单词的概率。</li>
</ul>

<p><img src="/images/posts/论文/bert mlm.png" alt="" /></p>

<p>​	Bert损失函数只考虑掩码值的预测，而忽略非掩码词的预测，因此模型的收敛速度比定向模型慢，这一特征被其增强的上下文感知所抵消。</p>

<h3 id="nsp">NSP</h3>

<p>​	在Bert训练过程中，模型接受成对的句子作为输入，并学习预测成对中的第二个句子是否是原始文档中后续句子。在训练过程中，50%的输入是一对，其中第二个句子是原始文档中的后续句子，而另外50%的输入是从语料库中随机选择的一个句子作为第二个句子。</p>

<p>​	为了帮助模型区分训练中的两个句子，输入在进入模型之前按以下方式处理：</p>

<ul>
  <li>在第一个句子的开头插入一个[CLS]标记，在每个句子的末尾插入一个[SEP]标记；</li>
  <li>表示句子A或句子B的句子嵌入被添加到每个标记中；</li>
  <li>将位置嵌入添加到每个标记以指示其在序列中的位置。</li>
</ul>

<p><img src="/images/posts/论文/bert 输入.png" alt="" /></p>

<p>​	为了预测第二个句子是否确实与第一个句子相关，执行以下步骤：</p>

<ul>
  <li>整个输入序列经过Transformer模型</li>
  <li>[CLS]标记的输出使用简单的分类层转换为$\color{blue}{2\times 1}$形状的向量</li>
  <li>用softmax计算Is Next Sequence的概率</li>
</ul>

<p>在训练Bert模型时，Masked LM 和 Next Sentence Prediction 是一起训练的，目标是最小化两种策略的组合损失函数。</p>

<h2 id="微调">微调</h2>

<p>​	将Bert用于特定的任务相对简单，可以用于各种各样的语言任务，而只在核心模型中增加一个小层</p>

<ul>
  <li>通过在[CLS]标记的Transformer输出顶部添加分类层，完成诸如情感分析之类的分类任务与Next Sentence分类类似；</li>
  <li>在问答任务（例如SQuAD v1.1）中，模型收到一个关于文本序列的问题，并需要在序列中标记答案，使用Bert，可以通过学习标记答案开始和结束的两个额外向量来训练问答模型；</li>
  <li>在命名实体识别中，接受一个文本序列，并需要标记文本中出现的各种类型的实体（人、组织、地点等）。使用Bert，可以通过将每个标记的输出向量输入到预测NER标签分类层来训练NER模型。</li>
</ul>

<h2 id="训练相关">训练相关</h2>

<ul>
  <li>模型的大小很重要，即使规模很大。Bert large拥有3.45亿个参数，是同类模型中最大的。他在小规模任务上明显优于Bert base，后者“仅”1.1亿个参数；</li>
  <li>有了足够的训练数据，更多的训练步骤==更高的准确度，eg：在MNLI任务上，与具有相同批量大小的500K步相比，Bert base在1M（批量大小为128000字）上训练时的准确度提高了1%；</li>
  <li>Bert的双向方法（MLM）的收敛速度比从左到右的方法慢（因为每批中只有15%的单词被预测），但在少量预训练步骤后，双向训练仍然优于从左到右的训练</li>
</ul>

<p><img src="/images/posts/论文/bert 训练 step.png" alt="" /></p>

<h2 id="参考文献">参考文献</h2>

<p><a href="https://www.lyrn.ai/2018/11/07/explained-bert-state-of-the-art-language-model-for-nlp/">1、BERT Explained</a>: State of the art language model for NLP</p>

<p><a href="https://zhuanlan.zhihu.com/p/95594311">2、关于BERT的若干问题整理记录</a></p>

  </section>

</article>

<section>

            <div class="content-play">
              <p><a href="javascript:void(0)" onclick="dashangToggle()" class="dashang" title="打赏，支持一下">打赏一个呗</a></p>
              <div class="hide_box-play"></div>
              <div class="shang_box-play">
                <a class="shang_close-play" href="javascript:void(0)" onclick="dashangToggle()" title="关闭"><img src="/images/payimg/close.jpg" alt="取消" /></a>
                <div class="shang_tit-play">
                  <p>感谢您的支持，我会继续努力的!</p>
                </div>
                <div class="shang_payimg">
                    <img src="/images/payimg/alipayimg.jpg" alt="扫码支持" title="扫一扫" />
                </div>
              <div class="shang_payimg">    
                    <img src="/images/payimg/weipayimg.jpg" alt="扫码支持" title="扫一扫" />
                </div>
                <div class="pay_explain">扫码打赏，你说多少就多少</div>
                <div class="shang_payselect">
                  <div class="pay_item checked" data-id="alipay">
                    <span class="pay_logo"><img src="/images/payimg/alipay.jpg" alt="支付宝" /></span>
                  </div>
                  <div class="pay_item" data-id="weipay">
                    <span class="pay_logo"><img src="/images/payimg/wechat.jpg" alt="微信" /></span>
                  </div>
                </div>
                <div class="shang_info-play">
                  <p>打开<span id="shang_pay_txt">微信</span>扫一扫，即可进行扫码打赏哦</p>
                </div>
              </div>
            </div>
            <script type="text/javascript">
            function dashangToggle(){
              $(".hide_box-play").fadeToggle();
              $(".shang_box-play").fadeToggle();
            }
            </script>

            <div style="text-align:center;margin:50px 0; font:normal 14px/24px 'MicroSoft YaHei';"></div>

            <style type="text/css">
              .content-play{width:80%;margin-top: 20px;margin-bottom: 10px;height:40px;}
              .hide_box-play{z-index:999;filter:alpha(opacity=50);background:#666;opacity: 0.5;-moz-opacity: 0.5;left:0;top:0;height:99%;width:100%;position:fixed;display:none;}
              .shang_box-play{width:540px;height:540px;padding:10px;background-color:#fff;border-radius:10px;position:fixed;z-index:1000;left:50%;top:50%;margin-left:-280px;margin-top:-280px;border:1px dotted #dedede;display:none;}
              .shang_box-play img{border:none;border-width:0;}
              .dashang{display:block;width:100px;margin:5px auto;height:25px;line-height:25px;padding:10px;background-color:#E74851;color:#fff;text-align:center;text-decoration:none;border-radius:10px;font-weight:bold;font-size:16px;transition: all 0.3s;}
              .dashang:hover{opacity:0.8;padding:15px;font-size:18px;}
              .shang_close-play{float:right;display:inline-block;
                margin-right: 10px;margin-top: 20px;
              }
              .shang_logo{display:block;text-align:center;margin:20px auto;}
              .shang_tit-play{width: 100%;height: 75px;text-align: center;line-height: 66px;color: #a3a3a3;font-size: 16px;background: url('/images/payimg/cy-reward-title-bg.jpg');font-family: 'Microsoft YaHei';margin-top: 7px;margin-right:2px;}
              .shang_tit-play p{color:#a3a3a3;text-align:center;font-size:16px;}
              .shang_payimg{width:140px;padding:10px;padding-left: 80px; /*border:6px solid #EA5F00;**/margin:0 auto;border-radius:3px;height:140px;display:inline-block;}
              .shang_payimg img{display:inline-block;margin-right:10px;float:left;text-align:center;width:140px;height:140px; }
              .pay_explain{text-align:center;margin:10px auto;font-size:12px;color:#545454;}
              .shang_payselect{text-align:center;margin:0 auto;margin-top:40px;cursor:pointer;height:60px;width:500px;margin-left:110px;}
              .shang_payselect .pay_item{display:inline-block;margin-right:140px;float:left;}
              .shang_info-play{clear:both;}
              .shang_info-play p,.shang_info-play a{color:#C3C3C3;text-align:center;font-size:12px;text-decoration:none;line-height:2em;}
            </style>

       <ul class="pager">
        
        <li class="previous">
            <a href="/2021/12/NER%E8%B0%88%E5%8F%A4%E8%AE%BA%E4%BB%8A/" data-toggle="tooltip" data-placement="top" title="NER谈古论今">上一篇：  <span>NER谈古论今</span>
            </a>
        </li>
        
        
        <li class="next">
            <a href="/2022/04/GPT1%E5%88%B0GPT3/" data-toggle="tooltip" data-placement="top" title="GPT1-GPT3">下一篇：  <span>GPT1-GPT3</span>
            </a>
        </li>
        
    </ul>
</section>

<section class="post-comments">
<!-- 来必力City版安装代码 -->
<div id="lv-container" data-id="city" data-uid="MTAyMC81NTEyNC8zMTU5Mg==">
	<script type="text/javascript">
var refer = "<?=get_permalink($id);?>".replace("http://","");
   (function(d, s) {
       var j, e = d.getElementsByTagName(s)[0];

       if (typeof LivereTower === 'function') { return; }

       j = d.createElement(s);
       j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
       j.async = true;

       e.parentNode.insertBefore(j, e);
   })(document, 'script');
	</script>
<noscript> 为正常使用来必力评论功能请激活JavaScript</noscript>
</div>
<!-- City版安装代码已完成 -->
</section>




            <section class="footer">
    <footer>
        <div class = "footer_div">  
        <nav class="cover-navigation navigation--social">
          <ul class="navigation">

          
          <!-- Github -->
          <li class="navigation__item_social">
            <a href="https://github.com/monkeytb" title="@monkeytb 的 Github" target="_blank">
              <div class="footer-social-icon" style="background:url(/images/github.png);"></div>
            </a>
          </li>
          

          

          

          

          

          
          


          
          <!-- Email -->
          <li class="navigation__item_social">
            <a href="mailto:13689446615@163.com" title="Contact me">
              <div class="footer-social-icon" style="background:url(/images/email.png);"></div>
            </a>
          </li>
          

          </ul>
        </nav>

        </div>

        <div class = "footer_div">  
           <p class="copyright text-muted">
            Copyright &copy; YiYao 2022 Theme by <a href="https://monkeytb.github.io">MonkeyTB</a> |
            <iframe
                style="margin-left: 2px; margin-bottom:-5px;"
                frameborder="0" scrolling="0" width="91px" height="20px"
                src="https://ghbtns.com/github-btn.html?user=monkeytb&repo=monkeytb.github.io&type=star&count=true" >
            </iframe>
            </p>
        	<div align="right">
    			<link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.3.0/css/font-awesome.min.css">

          <!-- 访问统计 -->
          <span id="busuanzi_container_site_pv">
            本站总访问量
            <span id="busuanzi_value_site_pv"></span>次
          </span>

        </div>
        <div>
    </footer>
</section>

        </div>
    </div>
    
    <script type="text/javascript" src="//code.jquery.com/jquery-1.11.3.min.js"></script>
<script type="text/javascript" src="/js/main.js"></script>

<script type="text/javascript" src="/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



    
  </body>

</html>
