I"<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>

<p>seq2seq是一种循环神经网络的变种，包括编码器和解码器两部分，可用于机器翻译、对话系统、自动摘要</p>

<h1 id="常见seq2seq结构">常见seq2seq结构</h1>

<p>seq2seq是一种重要的RNN模型，也称为Encoder-Decoder模型，可以理解为 N<em>M</em>N<em>∗</em>M* 的模型，模型包含两部分，Encoder部分编码序列的信息，将任意长度的信息编码到一个向量 c<em>c</em> 里，而Decoder部分通过向量 c<em>c</em> 将信息解码，并输出序列，常见的结构如下几种：</p>

<p>第一种 seq2seq结构</p>

<p><img src="/images/posts/自然语言处理/seq2seq1.png" alt="" /></p>

<p>第二种 seq2seq结构</p>

<p><img src="/images/posts/自然语言处理/seq2seq2.png" alt="" /></p>

<p>第三种 seq2seq结构</p>

<p><img src="/images/posts/自然语言处理/seq2seq3.png" alt="" /></p>

<h2 id="encoder">Encoder</h2>

<p>· 这三种模型结构的主要区别在于Decoder上，Encoder是一样的，Encoder部分的RNN通过接受输入 $X$ ，通过RNN编码所有信息到$c$（所有神经元最后的输出，不要中间神经元的输出）。</p>

<h2 id="decoder">Decoder</h2>

<p>· 第一种Decoder，结构简单，将Encoder编码信息$c$作为Decoder解码隐层的初始输入，后续神经元接受上一神经元的隐层输出状态$h`$</p>

<p>· 第二种Decoder，将Encoder编码信息 $c$作为Decoder解码隐层每个神经元的输入，而不在作为隐层的初始输入；</p>

<p>·  第三种Decoder，再第二种的基础上，每个神经元的输入有了两部分，一部分是Encoder编码信息 $c$，另一部分是Decoder上个神经元的输出，两部分通过不同的权重矩阵来作为当前神经元的输入。</p>

<h1 id="使用trick">使用trick</h1>

<h2 id="attention">Attention</h2>

<p>seq2seq模型中，Encoder总是将源句子的信息编码到一个固定长度的上下文 $c$ 中，然后Decoder的过程中 $c$总是不变的，这样就存在几个问题：</p>

<ol>
  <li>当源句子较长时，很难用一个定长的向量 c<em>c</em> 表示完所有的信息；</li>
  <li>RNN存在梯度小时的问题，只使用最后一个神经元得到的向量 c<em>c</em> 效果不理想；</li>
  <li>与人类阅读时的注意力方式不同，人类总是把注意力放在当前句子上</li>
</ol>

<p>Attention（注意力机制），是一种将模型注意力放在当前翻译单词上的一种机制。例如翻译“I have a cat”，翻译我时注意力在”I“上，翻译猫时注意力在”cat“上。</p>

<p>使用Attention后，Decoder的输入就不是固定的上下文向量 $c$了，而是根据当前翻译的信息，计算当前  $c$。</p>

<p>Attention</p>

<p><img src="/images/posts/自然语言处理/attention.png" alt="" /></p>

<p>Attention需要保留Encoder每一个神经元的隐藏层向量 $h$ ，然后Decoder的第$t$个神经元要根据上一个神经元的隐藏层向量 $h`_{t-1}$计算当前状态与Encoder每一个神经元的相关性 $e_t$。 $e_t$是一个N维的向量（Encoder神经元个数维N），若$e_t$第$i$维越大，则说明当前节点与Encoder第$i$个神经元的相关性越大。$e_t$的计算方式有很多，即相关性系数的计算函数$a$有很多种：</p>

<p><img src="/images/posts/自然语言处理/attention_scal.png" alt="img" /></p>

<p>上面得到相关性向量 $e_t$后，需要进行归一化，使用 softmax 归一化。然后用归一化后的系数融合 Encoder 的多个隐藏层向量得到 Decoder 当前神经元的上下文向量 $c_t$：</p>

<p><img src="/images/posts/自然语言处理/attention_scal_softmax.png" alt="img" /></p>

<p>Attention 计算上下文$c$</p>

<p>总体流程图</p>

<p><img src="/images/posts/自然语言处理/attention_all.png" alt="img" /></p>

<h2 id="teacher-forcing">Teacher Forcing</h2>

<p>Teacher Forcing用于训练阶段，主要针对上面第三种Decoder模型来说，第三种Decoder模型输入包含了上一时刻的输出神经元 $y’$，这样就会有个问题，如果上一时刻$y’$是错误的，则后面的神经元也会很容易错误，导致错误传递下去。</p>

<p>Teacher Forcing在一定程度上可以解决这个问题，在训练阶段，Decoder模型每个神经元接受的输入是正确的label，而并未上一时刻神经元的输出，对比如下：</p>

<p><img src="/images/posts/自然语言处理/teach_1.png" alt="img" /></p>

<p>不适用 Teacher Forcing</p>

<p><img src="/images/posts/自然语言处理/teach_2.png" alt="img" /></p>

<p>使用Teacher Forcing</p>

<h2 id="beam-search">Beam Search</h2>

<p>Beam Search 方法不用于训练的过程，而是用在测试的。在每一个神经元中，我们都选取当前输出概率值最大的 <strong>top k</strong> 个输出传递到下一个神经元。下一个神经元分别用这 k 个输出，计算出 L 个单词的概率 (L 为词汇表大小)，然后在 kL 个结果中得到 <strong>top k</strong> 个最大的输出，重复这一步骤。</p>

<h1 id="参考">参考</h1>

<p>https://www.jianshu.com/p/80436483b13b</p>

<p>https://towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3</p>
:ET